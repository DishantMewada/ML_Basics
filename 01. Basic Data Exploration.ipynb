{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630f0750",
   "metadata": {},
   "source": [
    "## Step 01: Exploring The Data \n",
    "## 01. Melnourne Home Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56298408",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 01: Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "# save filepath to variable for easier access\n",
    "melbourne_file_path = './data/melbourne-housing-snapshot/melb_data.csv'\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "melbourne_home_data = pd.read_csv(melbourne_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a summary of the data in Melbourne data\n",
    "melbourne_home_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1531bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 5 rows of the data\n",
    "melbourne_home_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd6c08c",
   "metadata": {},
   "source": [
    "## Step 02: Selecting Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b39338",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_home_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f004e9d",
   "metadata": {},
   "source": [
    "## Drop Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63741e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize null entries first\n",
    "import seaborn as sns\n",
    "sns.heatmap(melbourne_home_data.isnull(), cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_home_data = melbourne_home_data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_home_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568eb6b2",
   "metadata": {},
   "source": [
    "## Step 03: Selecting The Prediction Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c316e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = melbourne_home_data.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8218e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0afa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f414685",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_target = ['Price']\n",
    "y = melbourne_home_data[melbourne_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc4a0c",
   "metadata": {},
   "source": [
    "## Step 04: Choosing \"Features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = melbourne_home_data[melbourne_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55dc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338b064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3359fa",
   "metadata": {},
   "source": [
    "## Step 05: Building Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053eb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811381d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define model\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1) # random_state provides same result in each run : good practice\n",
    "# Step 2: Fit model - Capture patterns from provided data. This is the heart of modeling.\n",
    "melbourne_model.fit(X, y) \n",
    "# Step 3: Predict\n",
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "pred = melbourne_model.predict(X.head()) # X.head() makes it in-sample prediction\n",
    "print(pred)\n",
    "# Step 4: Evaluate - Determine how accurate the model's predictions are.\n",
    "'''    Confusion matrix\n",
    "    Accuracy\n",
    "    Precision\n",
    "    Recall\n",
    "    Specificity\n",
    "    F1 score\n",
    "    Precision-Recall or PR curve\n",
    "    ROC (Receiver Operating Characteristics) curve\n",
    "'''\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,precision_score,recall_score,f1_score\n",
    "    \n",
    "# MAE - takes abs(errors) ie |real-predicted| and takes average of all\n",
    "mae = mean_absolute_error(y.head(), pred)  \n",
    "print('MAE: %f' % mae)\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y.head(), pred) # y_true, y_pred\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y.head(), pred, average='micro')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y.head(), pred, average='micro')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y.head(), pred, average='micro')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9761830",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common practice is to split the data after assigning features and target\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "# Step 0: Split the model into train and test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.20, random_state=0) \n",
    "# Step 1: Define model\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "# Step 2: Fit model\n",
    "melbourne_model.fit(X_train, y_train)\n",
    "# Step 3: Predict\n",
    "pred = melbourne_model.predict(X_test)\n",
    "# Step 4: Evaluate\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print('MAE: %f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde50eaa",
   "metadata": {},
   "source": [
    "\n",
    "## Overfitting and Underfitting\n",
    "<img src=\"https://i.imgur.com/2q85n9s.png\" width=500 height=500 />\n",
    "\n",
    "### Overfitting: Good performance on the training data, poor generliazation to other data.\n",
    "### Underfitting: Poor performance on the training data and poor generalization to other data\n",
    "\n",
    "Overfitting refers to a model that models the training data too well.\n",
    "\n",
    "Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. The problem is that these concepts do not apply to new data and negatively impact the models ability to generalize.\n",
    "\n",
    "Underfitting refers to a model that can neither model the training data nor generalize to new data.\n",
    "\n",
    "An underfit machine learning model is not a suitable model and will be obvious as it will have poor performance on the training data.\n",
    "\n",
    "Ideally, you want to select a model at the sweet spot between underfitting and overfitting. But is very difficult to do in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0bcd60",
   "metadata": {},
   "source": [
    "There are two important techniques that you can use when evaluating machine learning algorithms to limit overfitting:\n",
    "\n",
    "Use a resampling technique to estimate model accuracy: The most popular resampling technique is k-fold cross validation. It allows you to train and test your model k-times on different subsets of training data and build up an estimate of the performance of a machine learning model on unseen data.\n",
    "\n",
    "Hold back a validation dataset: A validation dataset is simply a subset of your training data that you hold back from your machine learning algorithms until the very end of your project. After you have selected and tuned your machine learning algorithms on your training dataset you can evaluate the learned models on the validation dataset to get a final objective idea of how the models might perform on unseen data. Using cross validation is a gold standard in applied machine learning for estimating model accuracy on unseen data. If you have the data, using a validation dataset is also an excellent practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba1dc5",
   "metadata": {},
   "source": [
    "# 02. Iowa Home data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da89090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "# save filepath to variable for easier access\n",
    "iowa_file_path = './data/iowa_home_data/train.csv'\n",
    "# read the data and store data in DataFrame titled melbourne_data\n",
    "iowa_home_data = pd.read_csv(iowa_file_path) \n",
    "# print a summary of the data in Melbourne data\n",
    "iowa_home_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "iowa_home_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Checking various null entries in the dataset, with the help of heatmap\n",
    "sns.heatmap(iowa_home_data.isnull(), cbar=False)\n",
    "# check the columns full of null values are relevant for features\n",
    "# no need to drop those rows, just dont include them in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1902c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract three relevant columns from home data into a new dataframe\n",
    "df = iowa_home_data[['YrSold', 'YearRemodAdd', 'YearBuilt']]\n",
    "# Create a histogram from each column sharing the same x-axis\n",
    "df.plot.hist(figsize=(12, 10), subplots=True, bins=50); # plot requires matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ded4a",
   "metadata": {},
   "source": [
    "## how old is the newest home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iowa_home_data[['YrSold','YearBuilt']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c541a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "current_year = date.today().year;\n",
    "newest_home_age = (current_year - iowa_home_data.loc[:,'YearBuilt'].max()) #df.loc[rows:columns]\n",
    "newest_home_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1188d94",
   "metadata": {},
   "source": [
    "## What is the average lot size (rounded to nearest integer)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5067af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iowa_home_data[['LotArea']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_lot_size = iowa_home_data.loc[:,'LotArea'].mean()\n",
    "avg_lot_size = round(avg_lot_size, 0)\n",
    "avg_lot_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20448bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iowa_home_data.SalePrice\n",
    "feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = iowa_home_data[feature_columns]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split as split\n",
    "X_train, X_test, y_train, y_test = split(X, y, random_state=0) \n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "iowa_home_model = DecisionTreeRegressor()\n",
    "\n",
    "iowa_home_model.fit(X_train, y_train)\n",
    "y_pred = iowa_home_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('DecisionTreeRegressor MAE:', mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "iowa_home_model = LinearRegression()\n",
    "\n",
    "iowa_home_model.fit(X_train, y_train)\n",
    "y_pred = iowa_home_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('LinearRegression MAE:', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3268c679",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7944213",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd692b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
